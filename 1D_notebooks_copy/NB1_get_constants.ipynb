{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5bfbce-97e4-4b65-8fc4-3266370bc1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import replay_structure.structure_models as models\n",
    "import replay_structure.metadata as meta\n",
    "import replay_structure.read_write as read_write\n",
    "import replay_structure.utils as utils\n",
    "\n",
    "import importlib\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97b92a-de1a-499a-ab69-dbe4ecbb2c0f",
   "metadata": {},
   "source": [
    "## Calculate SCALING FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6ba966-b3b6-45fe-9207-b534863246c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/masha/Documents/Studium/MIT/project/data/\"\n",
    "filename = DATA_PATH+'preprocessed_5cm.obj'\n",
    "with open(filename, \"rb\") as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    ratday_data = pickle.loads(raw_data)\n",
    "filename = DATA_PATH+'spikemat_5cm_15ms.obj'\n",
    "with open(filename, \"rb\") as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    ripple_data = pickle.loads(raw_data)\n",
    "filename = DATA_PATH+'run_snippets_spikemat_5cm_15ms.obj' \n",
    "with open(filename, \"rb\") as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    run_data = pickle.loads(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2590a62e-d48d-4990-a8b2-14c69adb8108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_run_periods(ratday, run_period_threshold_s=2):\n",
    "    run_lengths = (\n",
    "        ratday.velocity_info[\"run_ends\"] - ratday.velocity_info[\"run_starts\"]\n",
    "    )\n",
    "    run_periods_use = run_lengths > run_period_threshold_s\n",
    "    run_starts = ratday.velocity_info[\"run_starts\"][run_periods_use]\n",
    "    run_ends = ratday.velocity_info[\"run_ends\"][run_periods_use]\n",
    "    return np.vstack((run_starts, run_ends)).T\n",
    "\n",
    "run_times_s = select_run_periods(ratday_data)\n",
    "run_period_trajectories_cm = utils.get_trajectories(\n",
    "        ratday_data, run_times_s\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97293158-f690-49d8-869f-9f6cc052e42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_fit_line(run_mean_frs, ripple_mean_frs):\n",
    "    fit = np.linalg.lstsq(run_mean_frs[:,None], ripple_mean_frs)\n",
    "    return fit[0]\n",
    "\n",
    "def find_best_fit_line_alldata(movement_avg_fr_dict, swr_avg_fr_dict):\n",
    "    all_movement = np.array([0])\n",
    "    all_swr = np.array([0])\n",
    "    for i in range(len(movement_avg_fr_dict)):\n",
    "        all_movement = np.append(all_movement, movement_avg_fr_dict[i])\n",
    "        all_swr = np.append(all_swr, swr_avg_fr_dict[i])\n",
    "    return find_best_fit_line(all_movement, all_swr)\n",
    "\n",
    "run_mean_frs = ratday_data.place_field_data[\"mean_firing_rate_array\"][ratday_data.place_field_data[\"place_cell_ids\"]]\n",
    "ripple_mean_frs = ripple_data.ripple_info[\"popburst_mean_firing_rate_array\"]\n",
    "slope_best_fit = find_best_fit_line(run_mean_frs, ripple_mean_frs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bfead6-6ee2-46e6-bcd5-3c32dbfbbf61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PF_SCALING_FACTOR = slope_best_fit.mean().round(1)\n",
    "PF_SCALING_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264a60a-fe9d-4369-aa48-1a930c661d33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate VELOCITY_SCALING_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581ae77-5869-4d6c-b7ea-9b0db780d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/masha/Documents/Studium/MIT/project/data/\"\n",
    "filename = DATA_PATH+'_5cm_15ms_poisson_trajectories.obj'\n",
    "with open(filename, \"rb\") as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    ripple_trajectories = pickle.loads(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ad9656-3825-425a-bb82-18be7106d27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_total_spikes_vec(spikemats):\n",
    "    n_traj = len(spikemats)\n",
    "    total_spikes_vec = np.full(n_traj, np.nan)\n",
    "    for i in range(n_traj):\n",
    "        if spikemats[i] is not None:\n",
    "            total_spikes_vec[i] = spikemats[i].sum()\n",
    "    return total_spikes_vec\n",
    "\n",
    "def get_total_distance(trajectory):\n",
    "    return np.sum(np.sqrt(np.sum((trajectory[1:] - trajectory[:-1])**2, axis=1)))\n",
    "\n",
    "def get_velocity(trajectory, time_window_s):\n",
    "    distance = get_total_distance(trajectory)\n",
    "    duration_s = len(trajectory) * time_window_s\n",
    "    velocity = distance/duration_s\n",
    "    return velocity\n",
    "\n",
    "def get_velocity_vec(trajectories, time_window_s):\n",
    "    n_traj = len(trajectories)\n",
    "    velocity_cm_per_s = np.full(n_traj, np.nan)\n",
    "    for i in range(n_traj):\n",
    "        if trajectories[i] is not None:\n",
    "            velocity_cm_per_s[i] = get_velocity(trajectories[i], time_window_s)\n",
    "    return velocity_cm_per_s\n",
    "\n",
    "def get_distance_vec(trajectories):\n",
    "    n_traj = len(trajectories)\n",
    "    distance_vec = np.full(n_traj, np.nan)\n",
    "    for i in range(n_traj):\n",
    "        if trajectories[i] is not None:\n",
    "            distance_vec[i] = get_total_distance(trajectories[i])\n",
    "    return distance_vec[~np.isnan(distance_vec)]\n",
    "\n",
    "def get_n_time_windows(spikemats):\n",
    "    n_traj = len(spikemats)\n",
    "    total_spikes_vec = np.full(n_traj, np.nan)\n",
    "    for i in range(n_traj):\n",
    "        if spikemats[i] is not None:\n",
    "            total_spikes_vec[i] = spikemats[i].shape[0]\n",
    "    return total_spikes_vec[~np.isnan(total_spikes_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654d030-8b60-4bca-b474-8c12d660b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_ripples = get_velocity_vec(ripple_trajectories.most_likely_trajectories, .003)\n",
    "velocity_run_periods = get_velocity_vec(run_period_trajectories_cm[str(session)], 1/30)\n",
    "mean_velocity_ripples[i] = np.nanmean(velocity_ripples[str(session)])\n",
    "mean_velocity_run_periods[i] = np.nanmean(velocity_run_periods[str(session)])\n",
    "sd_velocity_ripples[i] = np.nanstd(velocity_ripples[str(session)])/np.sqrt(meta.N_SESSIONS)\n",
    "sd_velocity_run_periods[i] = np.nanstd(velocity_run_periods[str(session)])/np.sqrt(meta.N_SESSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ef22b-b4bf-4d9f-b390-609218fe00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VELOCITY_SCALING_FACTOR = np.mean(mean_velocity_ripples/mean_velocity_run_periods).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e83b397-72d4-4510-87a9-f6ced2c13aa1",
   "metadata": {},
   "source": [
    "## Calculate MAX_LIKELIHOOD_SD_METERS_RIPPLES and MAX_LIKELIHOOD_SD_METERS_RUN_SNIPPETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86414c48-1d5e-444b-94be-02ea27a37452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gridsearch result for ripple data\n",
    "bin_size_cm = 5\n",
    "time_window_ms = 15\n",
    "RESULT_PATH = \"/home/masha/Documents/Studium/MIT/project/1D/results\"\n",
    "filename = RESULT_PATH+'/ripples_'+str(bin_size_cm)+'cm_'+str(time_window_ms)+'ms_poisson.obj'\n",
    "with open(filename, \"rb\") as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    dif_marginalized_gridsearch = pickle.loads(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0ad05-2a60-4e92-a525-0cdf007218f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_sd_meters = dif_marginalized_gridsearch.marginalization_info[\"best_fit_gridsearch_params\"][\"sd_meters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee055cb-46c5-4a5c-a3af-21a6b0648418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode from diffusion gridsearch on all sessions\n",
    "MAX_LIKELIHOOD_SD_METERS_RIPPLES = stats.mode(dif_sd_meters)\n",
    "MAX_LIKELIHOOD_SD_METERS_RIPPLES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
